{
  "name": "Seller Quality Optimizer - Continue (Final Fix)",
  "nodes": [
    {
      "parameters": {
        "jsCode": "// Parse prompt and fetch context\nconst promptResponse = $input.first().json;\nlet dallePrompt;\n\n// 1. Try to parse the prompt\ntry {\n  let content = promptResponse.message?.content || promptResponse.text || '';\n  content = content.replace(/^```json\\s*/i, '').replace(/\\s*```$/i, '').trim();\n  const parsed = JSON.parse(content);\n  dallePrompt = parsed.dalle_prompt;\n} catch (e) {\n  dallePrompt = null;\n}\n\n// 2. Fetch Context from upstream\n// We look for ANY node that has product data\nlet contextNode;\nconst possibleNodes = ['Aggregate All Sentiments2', 'Aggregate All Sentiments', 'Aggregate Sentiments'];\n\nfor (const name of possibleNodes) {\n    try {\n        const items = $(name).all();\n        if (items.length > 0 && items[0].json.product) {\n            contextNode = items[0].json;\n            break;\n        }\n    } catch (e) {}\n}\n\n// If still missing, try to grab from input if it was passed through\nif (!contextNode && promptResponse.product) {\n    contextNode = promptResponse;\n}\n\nif (!contextNode) {\n    // Mock data if testing in isolation, or throw clearer error\n    // For now, let's try to proceed with what we have or error out\n    throw new Error(\"Could not find product context. Please ensure 'Aggregate All Sentiments' node exists and has run.\");\n}\n\nif (!dallePrompt) {\n    dallePrompt = `Product photography of ${contextNode.product.title}. Show realistic version based on customer complaints: ${contextNode.discrepancy_details ? contextNode.discrepancy_details[0] : 'quality issues'}. White background, studio lighting.`;\n}\n\nreturn {\n  json: {\n    ...contextNode,\n    dalle_prompt: dallePrompt\n  }\n};"
      },
      "id": "parse-dalle-prompt-fixed",
      "name": "Parse DALL-E Prompt",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2880,
        100
      ]
    },
    {
      "parameters": {
        "resource": "image",
        "operation": "generate",
        "model": "dall-e-3",
        "prompt": "={{ $json.dalle_prompt }}",
        "options": {
          "quality": "hd",
          "size": "1024x1024",
          "style": "natural",
          "n": 1
        }
      },
      "id": "gen-model-1",
      "name": "Gen Model 1 (DALL-E 3)",
      "type": "@n8n/n8n-nodes-langchain.openAi",
      "typeVersion": 1.8,
      "position": [
        3100,
        100
      ],
      "credentials": {
        "openAiApi": {
          "id": "YOUR_OPENAI_CREDENTIAL_ID",
          "name": "OpenAI Account"
        }
      }
    },
    {
      "parameters": {
        "resource": "image",
        "operation": "generate",
        "model": "dall-e-3",
        "prompt": "={{ $json.dalle_prompt }}",
        "options": {
          "quality": "hd",
          "size": "1024x1024",
          "style": "vivid",
          "n": 1
        }
      },
      "id": "gen-model-2",
      "name": "Gen Model 2 (GPT-Image-1)",
      "type": "@n8n/n8n-nodes-langchain.openAi",
      "typeVersion": 1.8,
      "position": [
        3100,
        350
      ],
      "credentials": {
        "openAiApi": {
          "id": "YOUR_OPENAI_CREDENTIAL_ID",
          "name": "OpenAI Account"
        }
      }
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineAll",
        "options": {}
      },
      "id": "merge-images",
      "name": "Merge Images",
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3,
      "position": [
        3350,
        225
      ]
    },
    {
      "parameters": {
        "jsCode": "// Consolidate Images and Context\nconst items = $input.all();\n\n// Fetch Context from the Parse node\nconst contextItems = $('Parse DALL-E Prompt').all();\nconst context = contextItems.length > 0 ? contextItems[0].json : {};\n\n// Helper to extract URL\nfunction findUrl(item) {\n    if (!item || !item.json) return 'No Data';\n    if (item.json.data && Array.isArray(item.json.data) && item.json.data[0] && item.json.data[0].url) {\n        return item.json.data[0].url;\n    }\n    if (item.json.url) return item.json.url;\n    return 'URL Not Found';\n}\n\n// Map images (Item 0 = Model 1, Item 1 = Model 2)\nconst url1 = items.length > 0 ? findUrl(items[0]) : 'Missing';\nconst url2 = items.length > 1 ? findUrl(items[1]) : 'Missing';\n\nreturn {\n  json: {\n    ...context, // Pass through all context\n    images: [\n        { model: 'DALL-E 3', url: url1 },\n        { model: 'GPT-Image-1', url: url2 }\n    ]\n  }\n};"
      },
      "id": "prepare-vision-data",
      "name": "Prepare Vision Data",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        3600,
        225
      ]
    },
    {
      "parameters": {
        "model": "gpt-4o",
        "messages": {
          "values": [
            {
              "content": "You are a product quality inspector. Compare these 2 AI-generated images against customer complaints.\n\nTask:\n1. Analyze each image URL provided.\n2. Score each (1-10) on how well it visually depicts the described discrepancies.\n3. Provide a detailed comparative analysis.\n\nOutput JSON:\n{\n  \"analysis\": [\n    {\"model\": \"DALL-E 3\", \"score\": number, \"notes\": \"string\"},\n    {\"model\": \"GPT-Image-1\", \"score\": number, \"notes\": \"string\"}\n  ],\n  \"best_model\": \"string\",\n  \"detailed_summary\": \"string\"\n}",
              "role": "system"
            },
            {
              "content": "=Discrepancies: {{ $json.discrepancy_details ? $json.discrepancy_details.join(', ') : 'None' }}\n\nImages:\n1. DALL-E 3: {{ $json.images[0].url }}\n2. GPT-Image-1: {{ $json.images[1].url }}\n\nAnalyze them.",
              "role": "user"
            }
          ]
        },
        "jsonOutput": true
      },
      "id": "llm-vision-judge",
      "name": "LLM Vision Judge",
      "type": "@n8n/n8n-nodes-langchain.openAi",
      "typeVersion": 1.8,
      "position": [
        3800,
        225
      ],
      "credentials": {
        "openAiApi": {
          "id": "YOUR_OPENAI_CREDENTIAL_ID",
          "name": "OpenAI Account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Format data for Sheets\nconst contextItems = $('Prepare Vision Data').all();\nconst context = contextItems.length > 0 ? contextItems[0].json : {};\nconst analysis = $input.first().json;\n\nconst getScore = (idx) => analysis.analysis && analysis.analysis[idx] ? analysis.analysis[idx].score : 'N/A';\n\n// Prepare string for Google Sheets (handling arrays safely)\nconst summary = context.discrepancy_details ? context.discrepancy_details.join(' | ') : 'No discrepancies';\n\nreturn {\n  json: {\n    asin: context.asin || 'N/A',\n    product_title: context.product ? context.product.title : 'N/A',\n    \n    overall_sentiment: context.overall_sentiment || 'N/A',\n    discrepancy_summary: summary,\n    \n    // Image 1\n    img1_url: context.images && context.images[0] ? context.images[0].url : 'N/A',\n    img1_score: getScore(0),\n    \n    // Image 2\n    img2_url: context.images && context.images[1] ? context.images[1].url : 'N/A',\n    img2_score: getScore(1),\n    \n    best_model: analysis.best_model || 'N/A',\n    vision_judgment: analysis.detailed_summary || 'N/A',\n    analyzed_at: new Date().toISOString()\n  }\n};"
      },
      "id": "format-final-data",
      "name": "Format Final Data",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4000,
        225
      ]
    },
    {
      "parameters": {
        "operation": "append",
        "documentId": {
          "__rl": true,
          "mode": "id",
          "value": "={{ $env.OUTPUT_SHEET_ID }}"
        },
        "sheetName": {
          "__rl": true,
          "mode": "name",
          "value": "Analysis Results"
        },
        "columns": {
          "mappingMode": "defineBelow",
          "value": {
            "ASIN": "={{ $json.asin }}",
            "Product": "={{ $json.product_title }}",
            "Sentiment": "={{ $json.overall_sentiment }}",
            "Summarized Review": "={{ $json.discrepancy_summary }}",
            "Image 1 URL": "={{ $json.img1_url }}",
            "Image 1 Score": "={{ $json.img1_score }}",
            "Image 2 URL": "={{ $json.img2_url }}",
            "Image 2 Score": "={{ $json.img2_score }}",
            "Best Model": "={{ $json.best_model }}",
            "Judgment": "={{ $json.vision_judgment }}",
            "Date": "={{ $json.analyzed_at }}"
          }
        },
        "options": {}
      },
      "id": "save-to-sheets",
      "name": "Save Analysis to Sheets",
      "type": "n8n-nodes-base.googleSheets",
      "typeVersion": 4.5,
      "position": [
        4200,
        225
      ],
      "credentials": {
        "googleSheetsOAuth2Api": {
          "id": "YOUR_GOOGLE_SHEETS_CREDENTIAL_ID",
          "name": "Google Sheets Account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "console.log('Analysis Saved to Sheets');\nreturn { json: $json };"
      },
      "id": "final-output",
      "name": "Final Output",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        4400,
        225
      ]
    }
  ],
  "connections": {
    "Parse DALL-E Prompt": {
      "main": [
        [
          {
            "node": "Gen Model 1 (DALL-E 3)",
            "type": "main",
            "index": 0
          },
          {
            "node": "Gen Model 2 (GPT-Image-1)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Gen Model 1 (DALL-E 3)": {
      "main": [
        [
          {
            "node": "Merge Images",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Gen Model 2 (GPT-Image-1)": {
      "main": [
        [
          {
            "node": "Merge Images",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Merge Images": {
      "main": [
        [
          {
            "node": "Prepare Vision Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Vision Data": {
      "main": [
        [
          {
            "node": "LLM Vision Judge",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LLM Vision Judge": {
      "main": [
        [
          {
            "node": "Format Final Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Final Data": {
      "main": [
        [
          {
            "node": "Save Analysis to Sheets",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Save Analysis to Sheets": {
      "main": [
        [
          {
            "node": "Final Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  }
}