{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62fb1bf8-b7a7-4833-95c0-9e5c4defb151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rzrizaldy/CodeFolder/genai-lab_homework/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/rzrizaldy/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/rzrizaldy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import json \n",
    "import os \n",
    "import io\n",
    "import re\n",
    "#import requests \n",
    "import dotenv \n",
    "import transformers\n",
    "import pypdf\n",
    "import faiss\n",
    "#import sqlite3\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from openai import OpenAI\n",
    "from sentence_transformers import util, SentenceTransformer\n",
    "from transformers import pipeline, BertTokenizer, BertModel\n",
    "from PyPDF2 import PdfReader  # For PDF text extraction\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "from dotenv import load_dotenv\n",
    "#from operator import itemgetter\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from llama_index.core.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad5bc89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.cluster import DBSCAN\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17986735-76c2-48b1-8d31-bcf55415e9a2",
   "metadata": {},
   "source": [
    "# **Setting up Python Environment**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46361200-b3d1-4823-9303-b0f8d03dad21",
   "metadata": {},
   "source": [
    "## Instructions for setting up your .env file:\n",
    "\n",
    "1. Create a .env file in the same directory as this notebook\n",
    "\n",
    "2. Add the following lines to the .env file:\n",
    "\n",
    "    OPENAI_API_KEY=<your_openai_api_key>\n",
    "\n",
    "    HF_TOKEN=<your_huggingface_token>\n",
    "\n",
    "3. Replace the placeholders with your actual keys.\n",
    "\n",
    "4. Save the file.\n",
    "\n",
    "5. Restart the kernel to ensure the keys are loaded correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9284d476-6781-4e88-8116-c26483813fe3",
   "metadata": {},
   "source": [
    "# Load API Keys into the Notebook Environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "755afda5-3489-41c9-9ec9-238d5f80222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "HF_TOKEN = os.getenv('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5afa299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_api_keys():\n",
    "    \"\"\"\n",
    "    Checks if OpenAI and HuggingFace API keys are loaded and ready.\n",
    "\n",
    "    Prints the status and returns a status code.\n",
    "    \n",
    "    Returns:\n",
    "        int: Status code (0=all keys present, 1=missing OpenAI, 2=missing HF, 3=both missing)\n",
    "    \"\"\"\n",
    "    openai_key = os.getenv('OPENAI_API_KEY')\n",
    "    hf_key = os.getenv('HF_TOKEN')\n",
    "\n",
    "    openai_ok = bool(openai_key and openai_key.strip())\n",
    "    hf_ok = bool(hf_key and hf_key.strip())\n",
    "    \n",
    "    status_code = 0\n",
    "    if not openai_ok and not hf_ok:\n",
    "        print(\"❌ Both OpenAI and HuggingFace API keys are missing.\")\n",
    "        status_code = 3\n",
    "    elif not openai_ok:\n",
    "        print(\"❌ OpenAI API key is missing.\")\n",
    "        status_code = 1\n",
    "    elif not hf_ok:\n",
    "        print(\"❌ HuggingFace API key is missing.\")\n",
    "        status_code = 2\n",
    "    else:\n",
    "        print(\"✅ Both OpenAI and HuggingFace API keys are loaded successfully.\")\n",
    "        status_code = 0\n",
    "\n",
    "    return status_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10fd605e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Both OpenAI and HuggingFace API keys are loaded successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_api_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb469919-5b78-4ecc-bff8-6b7a8cdb6a19",
   "metadata": {},
   "source": [
    "# Custom Functions for Chunking the CMU Student Handbook & Measuring Computational Cost\n",
    "(Optional / not required for the homework that you use these functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19fd865d-e28b-40e9-a799-eae3d7699209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Text into Sentences\n",
    "def split_text_into_sentences_v1(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    return sentences\n",
    "\n",
    "def split_text_into_sentences_v2(text):\n",
    "    sentences = sent_tokenize(text, language='english')  # Default is usually 'english'\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b90dde5c-3e57-4064-9866-534125251e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to split the resumes into sentences and assign unique identifiers:\n",
    "\n",
    "def split_resumes_to_sentences(df, text_column):\n",
    "    \"\"\"\n",
    "    Split the resumes into individual sentences and assign unique identifiers.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing the resumes.\n",
    "        text_column (str): The name of the column containing the resume texts.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with each sentence and its corresponding unique identifier.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to hold the resulting data\n",
    "    sentences_list = []\n",
    "    \n",
    "    # Iterate through the DataFrame rows\n",
    "    for idx, row in df.iterrows():\n",
    "        # Tokenize the resume text into sentences\n",
    "        sentences = sent_tokenize(row[text_column])\n",
    "        \n",
    "        # Append each sentence along with the original index to the list\n",
    "        for sentence in sentences:\n",
    "            sentences_list.append((idx, sentence))\n",
    "    \n",
    "    # Convert the list to a DataFrame\n",
    "    sentences_df = pd.DataFrame(sentences_list, columns=['unique_identifier', 'sentence'])\n",
    "    \n",
    "    return sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a6edf2f-e975-4eb4-89ac-ad490332db35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Embedding Time: 0.6105 seconds\n",
      "Paraphrase Embedding Time: 0.0028 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_embedding_costs(text, model_name='all-MiniLM-L6-v2', eps=0.6, min_samples=2):\n",
    "    \"\"\"\n",
    "    Computes the computational cost (in terms of execution time) for creating\n",
    "    sentence embeddings and paraphrase embeddings.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The input text to be processed.\n",
    "    - model_name (str): The name of the model to use for embedding.\n",
    "    - eps (float): The epsilon value for DBSCAN clustering.\n",
    "    - min_samples (int): The minimum sample count for DBSCAN clustering.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple containing the execution times for sentence embeddings and paraphrase-level embeddings.\n",
    "    \"\"\"\n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    # Sentence Embedding Timing\n",
    "    start_time = time.time()\n",
    "    sentences = sent_tokenize(text)\n",
    "    sentence_embeddings = model.encode(sentences)\n",
    "    sentence_embedding_time = time.time() - start_time\n",
    "\n",
    "    # Paraphrase Embedding (Clustering) Timing\n",
    "    start_clustering_time = time.time()\n",
    "    clustering = DBSCAN(eps=eps, min_samples=min_samples, metric='cosine').fit(sentence_embeddings)\n",
    "    cluster_labels = clustering.labels_\n",
    "    \n",
    "    paraphrase_embeddings = []\n",
    "    for cluster_id in set(cluster_labels):\n",
    "        if cluster_id == -1:\n",
    "            continue\n",
    "        cluster_sentences = np.array(sentences)[cluster_labels == cluster_id]\n",
    "        paraphrase = ' '.join(cluster_sentences)\n",
    "        paraphrase_embeddings.append(paraphrase)\n",
    "    paraphrase_embedding_time = time.time() - start_clustering_time\n",
    "\n",
    "    return sentence_embedding_time, paraphrase_embedding_time\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    text = (\"This is a sample text. It has several sentences, meant to showcase \"\n",
    "            \"how embeddings are computed. Some of these sentences may be clustered \"\n",
    "            \"together, representing paraphrases or semantically similar groups.\")\n",
    "\n",
    "    sent_time, para_time = compute_embedding_costs(text)\n",
    "    print(f\"Sentence Embedding Time: {sent_time:.4f} seconds\")\n",
    "    print(f\"Paraphrase Embedding Time: {para_time:.4f} seconds\")\n",
    "\n",
    "# This function was created with GenerativeAI Assistance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d607795-c8dd-40c3-b704-282c7e4ed705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated FLOPs: 715797\n"
     ]
    }
   ],
   "source": [
    "def estimate_model_flops(model_name, text):\n",
    "    \"\"\"\n",
    "    Estimate the FLOPs for generating embeddings for a given text using a specified model.\n",
    "\n",
    "    Parameters:\n",
    "    - model_name (str): Model identifier from Hugging Face Transformers.\n",
    "    - text (str): Text to process.\n",
    "\n",
    "    Returns:\n",
    "    - FLOPs (int): An estimated number of floating point operations.\n",
    "    \"\"\"\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "    model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    input_ids = inputs['input_ids']\n",
    "\n",
    "    # Hooks for the operations\n",
    "    def hook_fn_forward(module, input, output):\n",
    "        # Attempt to access the tensor shape in a safer manner\n",
    "        input_shape = input[0].size()\n",
    "        \n",
    "        # A generalized fallback if shape isn't what's expected\n",
    "        if len(input_shape) == 2:  # Assuming shape [batch, seq_len] for simplicity\n",
    "            batch_size, seq_len = input_shape\n",
    "            # Hypothetical FLOPs calculation: For demonstration, let's assume it's just the product\n",
    "            flops = batch_size * seq_len\n",
    "        elif len(input_shape) > 2:  # Assuming more dimensions (e.g., embeddings)\n",
    "            flops = torch.prod(torch.tensor(input_shape))\n",
    "        else:\n",
    "            # In case of unsupported dimensions, set flops to 0 or some placeholder\n",
    "            flops = 0\n",
    "\n",
    "        # Storing calculated FLOPs in the module\n",
    "        if hasattr(module, '__flops__'):\n",
    "            module.__flops__ += flops\n",
    "        else:\n",
    "            module.__flops__ = flops\n",
    "\n",
    "    def add_hooks_to_model(model, hook_fn):\n",
    "        \"\"\"\n",
    "        Recursively add hook_fn to all the layers of the model.\n",
    "        \"\"\"\n",
    "        total_flops = 0\n",
    "        for layer in model.children():\n",
    "            if list(layer.children()):  # if the layer has children, recursively add hooks\n",
    "                total_flops += add_hooks_to_model(layer, hook_fn)\n",
    "            else:\n",
    "                if hasattr(layer, 'weight'):\n",
    "                    layer.register_forward_hook(hook_fn)\n",
    "                    layer.__flops__ = 0\n",
    "        return total_flops\n",
    "\n",
    "    add_hooks_to_model(model, hook_fn_forward)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _ = model(**inputs)\n",
    "\n",
    "    total_flops = sum([mod.__flops__ for mod in model.modules() if hasattr(mod, '__flops__')])\n",
    "\n",
    "    return total_flops\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    model_name = \"bert-base-uncased\"\n",
    "    text = \"This is an example sentence\"\n",
    "    flops = estimate_model_flops(model_name, text)\n",
    "    print(f\"Estimated FLOPs: {flops}\")\n",
    "\n",
    "# This function was created with GenerativeAI Assistance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee17ec0f-f60b-40e1-a7d0-d145aa07b3f7",
   "metadata": {},
   "source": [
    "# Load Data into the Notebook Environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2743ea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfreader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b6af6cf-349f-496b-a9ad-9aa212f2530a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document('cmu-student-policy-handbook.pdf')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = fitz.open(\"cmu-student-policy-handbook.pdf\")\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4124dc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **SECTION A IMPLEMENTATION - Semantic*\n",
    "\n",
    "**Chunking Method Chosen:** Semantic chunking (splits based on semantic similarity)  \n",
    "**Embedding Model:** sentence-transformers/all-mpnet-base-v2 (higher quality than MiniLM)  \n",
    "**Vector Store:** FAISS IndexFlatIP (Inner Product for cosine similarity)  \n",
    "**Retrieval Parameter k:** 5\n",
    "\n",
    "**Strategy Rationale:**\n",
    "- **Semantic Chunking**: Splits text at natural semantic boundaries where topic changes occur\n",
    "- **all-mpnet-base-v2**: 768-dim embeddings, superior quality for retrieval (ranked #1 on MTEB)\n",
    "- **Similarity threshold**: 0.7 to identify topic boundaries (when similarity drops, new chunk)\n",
    "- **Max chunk size**: 1000 chars to ensure chunks don't exceed embedding limits\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41addaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 674,632 characters from PDF\n",
      "Number of paragraphs (double newlines): 2\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION A: STEP 1 - Load and Prepare PDF Text\n",
    "# ============================================================================\n",
    "# Load the CMU Student Policy Handbook PDF and clean text\n",
    "reader = PdfReader(\"cmu-student-policy-handbook.pdf\")\n",
    "raw_text = \"\\n\".join((p.extract_text() or \"\") for p in reader.pages)\n",
    "\n",
    "# Clean text: normalize whitespace and line breaks\n",
    "raw_text = re.sub(r'\\r', '\\n', raw_text)\n",
    "raw_text = re.sub(r'[ \\t]+', ' ', raw_text)\n",
    "raw_text = re.sub(r'\\n{3,}', '\\n\\n', raw_text)\n",
    "raw_text = raw_text.strip()\n",
    "\n",
    "print(f\"Loaded {len(raw_text):,} characters from PDF\")\n",
    "print(f\"Number of paragraphs (double newlines): {raw_text.count(chr(10)*2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c2061ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model for semantic chunking: sentence-transformers/all-mpnet-base-v2\n",
      "Computing embeddings for 3585 sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 113/113 [00:24<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created 2655 text chunks using semantic chunking\n",
      "Average chunk length: 252 characters\n",
      "Min chunk length: 100 characters\n",
      "Max chunk length: 7319 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION A: STEP 2 - Chunk Text Using Semantic Chunking Method\n",
    "# ============================================================================\n",
    "# Method: Semantic chunking - splits based on semantic similarity between sentences\n",
    "# This identifies natural topic boundaries by detecting drops in semantic similarity\n",
    "# More intelligent than structural chunking as it respects meaning boundaries\n",
    "\n",
    "def semantic_chunk_text(\n",
    "    text: str, \n",
    "    embedding_model: SentenceTransformer,\n",
    "    max_chunk_size: int = 1000,\n",
    "    similarity_threshold: float = 0.7,\n",
    "    min_chunk_size: int = 100\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Semantic chunking: splits text at points where semantic similarity drops significantly.\n",
    "    This creates chunks that respect topic boundaries rather than arbitrary structural breaks.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text to chunk\n",
    "        embedding_model: SentenceTransformer model for computing embeddings\n",
    "        max_chunk_size: Maximum characters per chunk\n",
    "        similarity_threshold: Minimum similarity to keep sentences together (0-1)\n",
    "        min_chunk_size: Minimum characters per chunk\n",
    "    \n",
    "    Returns:\n",
    "        List of text chunks\n",
    "    \"\"\"\n",
    "    # Split text into sentences\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    if len(sentences) <= 1:\n",
    "        return [text] if text.strip() else []\n",
    "    \n",
    "    # Filter out very short sentences (likely noise)\n",
    "    sentences = [s.strip() for s in sentences if len(s.strip()) > 10]\n",
    "    if not sentences:\n",
    "        return [text] if text.strip() else []\n",
    "    \n",
    "    # Compute embeddings for all sentences\n",
    "    print(f\"Computing embeddings for {len(sentences)} sentences...\")\n",
    "    sentence_embeddings = embedding_model.encode(\n",
    "        sentences, \n",
    "        batch_size=32, \n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True\n",
    "    )\n",
    "    \n",
    "    # Find semantic break points\n",
    "    break_points = [0]  # Start with first sentence\n",
    "    current_chunk_start = 0\n",
    "    \n",
    "    for i in range(1, len(sentences)):\n",
    "        # Compute similarity between current and previous sentence\n",
    "        similarity = np.dot(sentence_embeddings[i-1], sentence_embeddings[i])\n",
    "        \n",
    "        # Check if we should break here\n",
    "        should_break = False\n",
    "        \n",
    "        # Break if similarity drops below threshold (semantic boundary)\n",
    "        if similarity < similarity_threshold:\n",
    "            should_break = True\n",
    "        \n",
    "        # Also break if adding this sentence would exceed max_chunk_size\n",
    "        current_chunk_text = \" \".join(sentences[current_chunk_start:i])\n",
    "        next_sentence = sentences[i]\n",
    "        if len(current_chunk_text) + len(next_sentence) + 1 > max_chunk_size:\n",
    "            should_break = True\n",
    "        \n",
    "        if should_break:\n",
    "            # Only create chunk if it meets minimum size\n",
    "            chunk_text = \" \".join(sentences[current_chunk_start:i])\n",
    "            if len(chunk_text) >= min_chunk_size or current_chunk_start == 0:\n",
    "                break_points.append(i)\n",
    "                current_chunk_start = i\n",
    "    \n",
    "    # Add final break point\n",
    "    break_points.append(len(sentences))\n",
    "    \n",
    "    # Create chunks from break points\n",
    "    chunks = []\n",
    "    for i in range(len(break_points) - 1):\n",
    "        chunk_sentences = sentences[break_points[i]:break_points[i+1]]\n",
    "        chunk_text = \" \".join(chunk_sentences).strip()\n",
    "        if chunk_text and len(chunk_text) >= min_chunk_size:\n",
    "            chunks.append(chunk_text)\n",
    "    \n",
    "    # Handle any remaining text\n",
    "    if not chunks:\n",
    "        chunks = [text]\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Initialize embedding model for semantic chunking (use same model as for retrieval)\n",
    "EMBED_MODEL_A = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "print(f\"Loading embedding model for semantic chunking: {EMBED_MODEL_A}\")\n",
    "semantic_embed_model = SentenceTransformer(EMBED_MODEL_A)\n",
    "\n",
    "# Create chunks using semantic chunking\n",
    "chunks_A = semantic_chunk_text(\n",
    "    raw_text, \n",
    "    embedding_model=semantic_embed_model,\n",
    "    max_chunk_size=1000,\n",
    "    similarity_threshold=0.7,\n",
    "    min_chunk_size=100\n",
    ")\n",
    "\n",
    "print(f\"\\nCreated {len(chunks_A)} text chunks using semantic chunking\")\n",
    "print(f\"Average chunk length: {np.mean([len(c) for c in chunks_A]):.0f} characters\")\n",
    "print(f\"Min chunk length: {min([len(c) for c in chunks_A])} characters\")\n",
    "print(f\"Max chunk length: {max([len(c) for c in chunks_A])} characters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbcc17ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using embedding model for retrieval: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 83/83 [00:23<00:00,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created embeddings: shape (2655, 768)\n",
      "Embedding dimension: 768 (768-dim for better quality)\n",
      "Embedding norm (should be ~1.0 for normalized): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION A: STEP 3 - Create Embeddings with High-Quality Model\n",
    "# ============================================================================\n",
    "# Embedding Model: sentence-transformers/all-mpnet-base-v2\n",
    "# - 768-dimensional embeddings (higher quality than MiniLM)\n",
    "# - Ranked #1 on MTEB (Massive Text Embedding Benchmark)\n",
    "# - Better semantic understanding for policy document retrieval\n",
    "# - Normalized for cosine similarity via Inner Product\n",
    "\n",
    "# Use the same embedding model that was used for semantic chunking\n",
    "# (Already loaded in previous cell, but we'll reference it here for clarity)\n",
    "EMBED_MODEL_A = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "embed_model_A = semantic_embed_model  # Reuse the model from semantic chunking\n",
    "print(f\"Using embedding model for retrieval: {EMBED_MODEL_A}\")\n",
    "\n",
    "# Create embeddings with normalization\n",
    "def embed_texts_A(texts: List[str]) -> np.ndarray:\n",
    "    \"\"\"Create normalized embeddings for Section A\"\"\"\n",
    "    embs = embed_model_A.encode(\n",
    "        texts, \n",
    "        batch_size=32, \n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True, \n",
    "        normalize_embeddings=True  # Normalize for cosine similarity\n",
    "    )\n",
    "    return embs.astype(\"float32\")\n",
    "\n",
    "emb_A = embed_texts_A(chunks_A)\n",
    "print(f\"\\nCreated embeddings: shape {emb_A.shape}\")\n",
    "print(f\"Embedding dimension: {emb_A.shape[1]} (768-dim for better quality)\")\n",
    "print(f\"Embedding norm (should be ~1.0 for normalized): {np.linalg.norm(emb_A[0]):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa0add63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index created with 2655 vectors\n",
      "Index type: IndexFlatIP\n",
      "Vector dimension: 768\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION A: STEP 4 - Build FAISS Vector Store\n",
    "# ============================================================================\n",
    "# Index Type: IndexFlatIP (Inner Product)\n",
    "# - Uses dot product for similarity (equivalent to cosine for normalized vectors)\n",
    "# - Exact search (no approximation) - perfect for our dataset size\n",
    "# - Suitable for normalized embeddings (cosine similarity = dot product)\n",
    "\n",
    "def build_ip_index_A(embs: np.ndarray):\n",
    "    \"\"\"Build FAISS Inner Product index for Section A\"\"\"\n",
    "    index = faiss.IndexFlatIP(embs.shape[1])  # Inner Product = cosine for normalized vectors\n",
    "    index.add(embs)\n",
    "    return index\n",
    "\n",
    "index_A = build_ip_index_A(emb_A)\n",
    "print(f\"FAISS index created with {index_A.ntotal} vectors\")\n",
    "print(f\"Index type: {type(index_A).__name__}\")\n",
    "print(f\"Vector dimension: {index_A.d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2d46dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing queries with optimized embedding model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 32.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 completed: 5 results retrieved (top score: 0.7960)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 29.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 2 completed: 5 results retrieved (top score: 0.8161)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 3 completed: 5 results retrieved (top score: 0.6821)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 74.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 4 completed: 5 results retrieved (top score: 0.6551)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 35.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 5 completed: 5 results retrieved (top score: 0.6489)\n",
      "\n",
      "Total results collected: 25 rows\n",
      "Expected: 25 rows (5 queries × 5 results)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION A: STEP 5 - Execute Queries (k=5)\n",
    "# ============================================================================\n",
    "# Query the vector store with the 5 required queries, retrieving top-5 results each\n",
    "# Using the optimized embedding model for better retrieval quality\n",
    "\n",
    "queries = [\n",
    "    \"What is the policy statement for the academic integrity policy?\",\n",
    "    \"What is the policy violation definition for cheating?\",\n",
    "    \"What is the policy statement for improper or illegal communications?\",\n",
    "    \"What are CMU's quiet hours?\",\n",
    "    \"Where are pets allowed on CMU?\"\n",
    "]\n",
    "\n",
    "def retrieve_A(query: str, index, chunks: List[str], k: int = 5):\n",
    "    \"\"\"Retrieve top-k results using Section A embedding model\"\"\"\n",
    "    # Embed query using the same model\n",
    "    qv = embed_texts_A([query])\n",
    "    # Search for top-k results\n",
    "    scores, idxs = index.search(qv, k)\n",
    "    out = []\n",
    "    for score, idx in zip(scores[0].tolist(), idxs[0].tolist()):\n",
    "        if idx == -1: continue  # Skip invalid indices\n",
    "        out.append((idx, float(score), chunks[idx]))\n",
    "    return out\n",
    "\n",
    "def clean_text_for_csv(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean text for Excel-compatible CSV export.\n",
    "    - Replace newlines with spaces (Excel-friendly)\n",
    "    - Remove excessive whitespace\n",
    "    - Ensure proper encoding\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    # Replace newlines and carriage returns with spaces\n",
    "    text = text.replace('\\r\\n', ' ').replace('\\n', ' ').replace('\\r', ' ')\n",
    "    # Replace multiple spaces with single space\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    # Strip leading/trailing whitespace\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "rows_A = []\n",
    "print(\"Executing queries with optimized embedding model...\\n\")\n",
    "for qi, q in enumerate(queries, 1):\n",
    "    res = retrieve_A(q, index_A, chunks_A, k=5)\n",
    "    for rank, (idx, score, text) in enumerate(res, 1):\n",
    "        # Clean the response text for Excel compatibility\n",
    "        cleaned_text = clean_text_for_csv(text)\n",
    "        rows_A.append({\n",
    "            \"Section\": \"A\",\n",
    "            \"Query #\": qi,\n",
    "            \"Query Text\": q,\n",
    "            \"k\": 5,\n",
    "            \"Response #\": rank,\n",
    "            \"chunk_id\": idx,\n",
    "            \"score\": round(score, 6),  # Round score for cleaner CSV\n",
    "            \"Response Text\": cleaned_text\n",
    "        })\n",
    "    print(f\"Query {qi} completed: {len(res)} results retrieved (top score: {res[0][1]:.4f})\")\n",
    "\n",
    "print(f\"\\nTotal results collected: {len(rows_A)} rows\")\n",
    "print(f\"Expected: 25 rows (5 queries × 5 results)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "262555cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Verification:\n",
      "  - Total rows: 25\n",
      "  - Expected: 25 rows (5 queries × 5 results)\n",
      "  - Unique queries: 5\n",
      "  - Results per query: [5, 5, 5, 5, 5]\n",
      "  - All k values: [5]\n",
      "\n",
      "✓ Results saved to partA_results.csv (Excel-compatible)\n",
      "✓ DataFrame shape: (25, 8)\n",
      "✓ Columns: ['Section', 'Query #', 'Query Text', 'k', 'Response #', 'chunk_id', 'score', 'Response Text']\n",
      "\n",
      "================================================================================\n",
      "CSV Format Verification (first line):\n",
      "================================================================================\n",
      "First line length: 85 characters\n",
      "First line preview: \"Section\",\"Query #\",\"Query Text\",\"k\",\"Response #\",\"chunk_id\",\"score\",\"Response Text\"\n",
      "...\n",
      "All fields quoted: True\n",
      "\n",
      "================================================================================\n",
      "Sample Results (First 5 rows):\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Section</th>\n",
       "      <th>Query #</th>\n",
       "      <th>Query Text</th>\n",
       "      <th>k</th>\n",
       "      <th>Response #</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>score</th>\n",
       "      <th>Response Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>What is the policy statement for the academic ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0.795959</td>\n",
       "      <td>Statement on Academic Integrity The Statement ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>What is the policy statement for the academic ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1373</td>\n",
       "      <td>0.725584</td>\n",
       "      <td>Existing University policies and principles on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>What is the policy statement for the academic ...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>0.724487</td>\n",
       "      <td>Academic Integrity Policy Students at Carnegie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>What is the policy statement for the academic ...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>69</td>\n",
       "      <td>0.698720</td>\n",
       "      <td>Practice of the Mission of Academic Integrity ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>What is the policy statement for the academic ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>107</td>\n",
       "      <td>0.693166</td>\n",
       "      <td>Fairness and Exemplary Behavior The preservati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Section  Query #                                         Query Text  k  \\\n",
       "0       A        1  What is the policy statement for the academic ...  5   \n",
       "1       A        1  What is the policy statement for the academic ...  5   \n",
       "2       A        1  What is the policy statement for the academic ...  5   \n",
       "3       A        1  What is the policy statement for the academic ...  5   \n",
       "4       A        1  What is the policy statement for the academic ...  5   \n",
       "\n",
       "   Response #  chunk_id     score  \\\n",
       "0           1        51  0.795959   \n",
       "1           2      1373  0.725584   \n",
       "2           3       120  0.724487   \n",
       "3           4        69  0.698720   \n",
       "4           5       107  0.693166   \n",
       "\n",
       "                                       Response Text  \n",
       "0  Statement on Academic Integrity The Statement ...  \n",
       "1  Existing University policies and principles on...  \n",
       "2  Academic Integrity Policy Students at Carnegie...  \n",
       "3  Practice of the Mission of Academic Integrity ...  \n",
       "4  Fairness and Exemplary Behavior The preservati...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION A: STEP 6 - Create Results DataFrame and Export to CSV\n",
    "# ============================================================================\n",
    "# Format results for homework submission spreadsheet template\n",
    "# Excel-compatible CSV with proper escaping and encoding\n",
    "\n",
    "partA_df = pd.DataFrame(rows_A)\n",
    "\n",
    "# Verify data structure\n",
    "print(\"Data Verification:\")\n",
    "print(f\"  - Total rows: {len(partA_df)}\")\n",
    "print(f\"  - Expected: 25 rows (5 queries × 5 results)\")\n",
    "print(f\"  - Unique queries: {partA_df['Query #'].nunique()}\")\n",
    "print(f\"  - Results per query: {partA_df.groupby('Query #').size().tolist()}\")\n",
    "print(f\"  - All k values: {partA_df['k'].unique()}\")\n",
    "\n",
    "# Export to Excel-compatible CSV\n",
    "# Using proper settings for Excel compatibility:\n",
    "# - quoting=csv.QUOTE_ALL: Quote ALL fields to handle commas in text properly\n",
    "# - This ensures commas within text don't break column separation\n",
    "# - doublequote=True: Double quotes for quotes within quoted fields\n",
    "import csv\n",
    "\n",
    "# Quote all fields to ensure commas in text don't break Excel import\n",
    "partA_df.to_csv(\n",
    "    \"partA_results.csv\", \n",
    "    index=False,\n",
    "    quoting=csv.QUOTE_ALL,  # Quote ALL fields - safest for Excel compatibility\n",
    "    doublequote=True,  # Use \"\" for quotes within quoted fields\n",
    "    lineterminator='\\n',  # Standard line terminator\n",
    "    encoding='utf-8'  # UTF-8 encoding\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Results saved to partA_results.csv (Excel-compatible)\")\n",
    "print(f\"✓ DataFrame shape: {partA_df.shape}\")\n",
    "print(f\"✓ Columns: {list(partA_df.columns)}\")\n",
    "\n",
    "# Verify CSV format - check first line to ensure proper quoting\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CSV Format Verification (first line):\")\n",
    "print(\"=\"*80)\n",
    "with open(\"partA_results.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    first_line = f.readline()\n",
    "    print(f\"First line length: {len(first_line)} characters\")\n",
    "    print(f\"First line preview: {first_line[:200]}...\")\n",
    "    print(f\"All fields quoted: {'\\\"' in first_line}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Sample Results (First 5 rows):\")\n",
    "print(\"=\"*80)\n",
    "partA_df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db76544-33a2-4628-a69e-25b853c38d73",
   "metadata": {},
   "source": [
    "# **Homework 2 Assignment**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83696b0-7564-4dc8-94f7-81281091796e",
   "metadata": {},
   "source": [
    "## **Section A. Experimenting with Vector Store Query Design (50 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f887d28e-de42-4af8-9f7f-82e7e93ad668",
   "metadata": {},
   "source": [
    "### **Choose a method to chunk the text data:**\n",
    "\n",
    "- [Semantic chunking](https://python.langchain.com/docs/modules/data_connection/document_transformers/semantic-chunker)\n",
    "\n",
    "- [Recursive chunking](https://python.langchain.com/docs/modules/data_connection/document_transformers/recursive_text_splitter)\n",
    "\n",
    "- [Character chunking](https://python.langchain.com/docs/modules/data_connection/document_transformers/character_text_splitter)\n",
    "\n",
    "- [Token chunking](https://python.langchain.com/docs/modules/data_connection/document_transformers/split_by_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0db0c94-cfb3-42c1-b0f7-4037db2cdf49",
   "metadata": {},
   "source": [
    "# Sentence Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83fd395-33d3-41f7-8d4d-ee8f7e62b254",
   "metadata": {},
   "source": [
    "### Choose a type of chunker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6e69d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /Users/rzrizaldy/CodeFolder/genai-lab_homework/.venv/lib/python3.13/site-packages (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install PyPDF2\n",
    "# Additional imports for alternative chunking methods\n",
    "from typing import List, Tuple\n",
    "from PyPDF2 import PdfReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96aad38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration: PDF path and embedding model\n",
    "# Update PDF_PATH to match your PDF filename\n",
    "PDF_PATH = \"cmu-student-policy-handbook.pdf\"  # or \"the-word-2023-24-12.11.23.pdf\"\n",
    "EMBED_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"  # Lightweight, fast embedding model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bcecc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded characters: 678695\n"
     ]
    }
   ],
   "source": [
    "# Load PDF and extract raw text\n",
    "# Extracts text from all pages and joins with newlines\n",
    "reader = PdfReader(PDF_PATH)\n",
    "raw_text = \"\\n\".join((p.extract_text() or \"\") for p in reader.pages)\n",
    "print(\"Loaded characters:\", len(raw_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae921257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning function: normalizes whitespace and line breaks\n",
    "# Removes carriage returns, collapses multiple spaces, limits consecutive newlines\n",
    "def clean_text(t: str) -> str:\n",
    "    t = re.sub(r'\\r', '\\n', t)  # Convert \\r to \\n\n",
    "    t = re.sub(r'[ \\t]+', ' ', t)  # Collapse spaces/tabs to single space\n",
    "    t = re.sub(r'\\n{3,}', '\\n\\n', t)  # Limit to max 2 consecutive newlines\n",
    "    return t.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "914ff881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paragraph-based chunking: splits by double newlines, respects max_chars with overlap\n",
    "# Overlap helps maintain context between chunks for better retrieval\n",
    "def chunk_by_paragraph(text: str, max_chars: int = 1200, overlap: int = 150):\n",
    "    text = clean_text(text)\n",
    "    paras = [p.strip() for p in text.split(\"\\n\\n\") if p.strip()]  # Split by paragraphs\n",
    "    chunks, buf = [], \"\"\n",
    "    \n",
    "    for p in paras:\n",
    "        if len(buf) + len(p) + 2 <= max_chars:  # +2 for \"\\n\\n\"\n",
    "            buf = (buf + \"\\n\\n\" + p) if buf else p\n",
    "        else:\n",
    "            if buf: chunks.append(buf)\n",
    "            # Add overlap from previous chunk for context continuity\n",
    "            if chunks and overlap > 0:\n",
    "                tail = chunks[-1][-overlap:]\n",
    "                buf = (tail + \"\\n\\n\" + p).strip()\n",
    "            else:\n",
    "                buf = p\n",
    "    if buf: chunks.append(buf)\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bba55a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence-based chunking: uses NLTK sentence tokenizer, respects max_chars with overlap\n",
    "# More granular than paragraph chunking, better for precise sentence-level retrieval\n",
    "def chunk_by_sentence(text: str, max_chars: int = 900, overlap: int = 120):\n",
    "    text = clean_text(text)\n",
    "    sents = nltk.tokenize.sent_tokenize(text)  # Split into sentences\n",
    "    chunks, buf = [], \"\"\n",
    "    \n",
    "    for s in sents:\n",
    "        if len(buf) + len(s) + 1 <= max_chars:  # +1 for space\n",
    "            buf = (buf + \" \" + s).strip() if buf else s\n",
    "        else:\n",
    "            if buf: chunks.append(buf)\n",
    "            # Add overlap from previous chunk for context continuity\n",
    "            if chunks and overlap > 0:\n",
    "                tail = chunks[-1][-overlap:]\n",
    "                buf = (tail + \" \" + s).strip()\n",
    "            else:\n",
    "                buf = s\n",
    "    if buf: chunks.append(buf)\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c579abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embedding model (load once, reuse for all embeddings)\n",
    "# all-MiniLM-L6-v2: 384-dim embeddings, fast and efficient\n",
    "embed_model = SentenceTransformer(EMBED_MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "287e7ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed texts: converts list of text chunks to normalized embedding vectors\n",
    "# Normalized embeddings enable cosine similarity via dot product (Inner Product)\n",
    "def embed_texts(texts: List[str]) -> np.ndarray:\n",
    "    embs = embed_model.encode(texts, batch_size=64, show_progress_bar=True,\n",
    "                              convert_to_numpy=True, normalize_embeddings=True)\n",
    "    return embs.astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3c53635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build FAISS Inner Product index: optimized for cosine similarity search\n",
    "# IndexFlatIP uses dot product (equivalent to cosine for normalized vectors)\n",
    "def build_ip_index(embs: np.ndarray):\n",
    "    index = faiss.IndexFlatIP(embs.shape[1])  # Inner Product = cosine for normalized vectors\n",
    "    index.add(embs)\n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8046c0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve function: searches index and returns top-k chunks with similarity scores\n",
    "# Returns list of (index, score, chunk_text) tuples sorted by relevance\n",
    "def retrieve(query: str, index, chunks: List[str], k: int = 5):\n",
    "    qv = embed_texts([query])  # Embed query (normalized; IP acts as cosine similarity)\n",
    "    scores, idxs = index.search(qv, k)  # Search for top-k results\n",
    "    out = []\n",
    "    for score, idx in zip(scores[0].tolist(), idxs[0].tolist()):\n",
    "        if idx == -1: continue  # Skip invalid indices\n",
    "        out.append((idx, float(score), chunks[idx]))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd02758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section A: Query the vector store with the 5 required queries (k=5)\n",
    "# These are the official homework queries for Section A\n",
    "queries = [\n",
    "    \"What is the policy statement for the academic integrity policy?\",\n",
    "    \"What is the policy violation definition for cheating?\",\n",
    "    \"What is the policy statement for improper or illegal communications?\",\n",
    "    \"What are CMU's quiet hours?\",\n",
    "    \"Where are pets allowed on CMU?\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dbdc2c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.04s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 86.69it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.35it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# Execute queries and collect results: retrieves top-5 chunks for each query\n",
    "# Stores results in structured format for easy analysis and CSV export\n",
    "rows_A = []\n",
    "for qi, q in enumerate(queries, 1):  # qi starts at 1 for query numbering\n",
    "    res = retrieve(q, index_A, chunks_A, k=5)  # Get top-5 results\n",
    "    for rank, (idx, score, text) in enumerate(res, 1):  # rank starts at 1\n",
    "        rows_A.append({\n",
    "            \"Section\": \"A\",\n",
    "            \"Query #\": qi,\n",
    "            \"Query Text\": q,\n",
    "            \"k\": 5,\n",
    "            \"Response #\": rank,\n",
    "            \"chunk_id\": idx,\n",
    "            \"score\": score,\n",
    "            \"Response Text\": text\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "decc5a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Section</th>\n",
       "      <th>Query #</th>\n",
       "      <th>Query Text</th>\n",
       "      <th>k</th>\n",
       "      <th>Response #</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>score</th>\n",
       "      <th>Response Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>What is the policy statement for the academic ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.393871</td>\n",
       "      <td>must not destroy that respect by their failure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>What is the policy statement for the academic ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.355402</td>\n",
       "      <td>1 \\n \\n \\n \\nThe Word: Student Handbook \\n2023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>What is the policy statement for the academic ...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.305320</td>\n",
       "      <td>sful Carnegie \\nMellon experience. \\n \\n \\nAmy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the policy violation definition for ch...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.264790</td>\n",
       "      <td>must not destroy that respect by their failure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the policy violation definition for ch...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.130284</td>\n",
       "      <td>sful Carnegie \\nMellon experience. \\n \\n \\nAmy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the policy violation definition for ch...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.070751</td>\n",
       "      <td>1 \\n \\n \\n \\nThe Word: Student Handbook \\n2023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>What is the policy statement for improper or i...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.212431</td>\n",
       "      <td>must not destroy that respect by their failure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>What is the policy statement for improper or i...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.087160</td>\n",
       "      <td>sful Carnegie \\nMellon experience. \\n \\n \\nAmy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>What is the policy statement for improper or i...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.078769</td>\n",
       "      <td>1 \\n \\n \\n \\nThe Word: Student Handbook \\n2023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>What are CMU's quiet hours?</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.195950</td>\n",
       "      <td>must not destroy that respect by their failure...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Section  Query #                                         Query Text  k  \\\n",
       "0       A        1  What is the policy statement for the academic ...  5   \n",
       "1       A        1  What is the policy statement for the academic ...  5   \n",
       "2       A        1  What is the policy statement for the academic ...  5   \n",
       "3       A        2  What is the policy violation definition for ch...  5   \n",
       "4       A        2  What is the policy violation definition for ch...  5   \n",
       "5       A        2  What is the policy violation definition for ch...  5   \n",
       "6       A        3  What is the policy statement for improper or i...  5   \n",
       "7       A        3  What is the policy statement for improper or i...  5   \n",
       "8       A        3  What is the policy statement for improper or i...  5   \n",
       "9       A        4                        What are CMU's quiet hours?  5   \n",
       "\n",
       "   Response #  chunk_id     score  \\\n",
       "0           1         2  0.393871   \n",
       "1           2         0  0.355402   \n",
       "2           3         1  0.305320   \n",
       "3           1         2  0.264790   \n",
       "4           2         1  0.130284   \n",
       "5           3         0  0.070751   \n",
       "6           1         2  0.212431   \n",
       "7           2         1  0.087160   \n",
       "8           3         0  0.078769   \n",
       "9           1         2  0.195950   \n",
       "\n",
       "                                       Response Text  \n",
       "0  must not destroy that respect by their failure...  \n",
       "1  1 \\n \\n \\n \\nThe Word: Student Handbook \\n2023...  \n",
       "2  sful Carnegie \\nMellon experience. \\n \\n \\nAmy...  \n",
       "3  must not destroy that respect by their failure...  \n",
       "4  sful Carnegie \\nMellon experience. \\n \\n \\nAmy...  \n",
       "5  1 \\n \\n \\n \\nThe Word: Student Handbook \\n2023...  \n",
       "6  must not destroy that respect by their failure...  \n",
       "7  sful Carnegie \\nMellon experience. \\n \\n \\nAmy...  \n",
       "8  1 \\n \\n \\n \\nThe Word: Student Handbook \\n2023...  \n",
       "9  must not destroy that respect by their failure...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame and save to CSV for homework submission\n",
    "# This matches the format required for the homework spreadsheet template\n",
    "partA_df = pd.DataFrame(rows_A)\n",
    "partA_df.to_csv(\"partA_results.csv\", index=False)\n",
    "partA_df.head(10)  # Display first 10 rows to verify results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2aa0a8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Chunk by paragraph, create embeddings, build index\n",
    "# This demonstrates the complete pipeline for paragraph-based chunking\n",
    "chunks_A = chunk_by_paragraph(raw_text, max_chars=1200, overlap=150)\n",
    "emb_A = embed_texts(chunks_A)\n",
    "index_A = build_ip_index(emb_A)\n",
    "len(chunks_A), index_A.ntotal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "31c96c68-c704-42de-9544-695a56db8034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is an example chunker. You don't have to use it. Email Sara with questions.\n",
    "\n",
    "# parser to split up PDF resume:\n",
    "text_parser = SentenceSplitter(\n",
    "    chunk_size=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541f3566-a26d-4146-8e2d-8ea7726c8ce4",
   "metadata": {},
   "source": [
    "#### **Chunker Choices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "172d1cf5-ffe4-4ff8-9380-fd63ffcaa7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunker choice #1:\n",
    "# Semantic Chunker: splits text into semantically-coherent chunks using NLTK sentence tokenization,\n",
    "# groups sentences to fit approximately within max_chars, and preserves context by overlapping.\n",
    "\n",
    "import nltk\n",
    "from typing import List\n",
    "\n",
    "def semantic_chunker(text: str, max_chars:1200, overlap:150) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split text into semantically-coherent chunks by grouping sentences such that\n",
    "    each chunk is approximately max_chars, with optional overlap in characters for contextual continuity.\n",
    "    Returns a list of text chunks.\n",
    "    \"\"\"\n",
    "    # Ensure sentence tokenizer is available\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    chunks = []\n",
    "    cur_chunk = \"\"\n",
    "    i = 0\n",
    "    while i < len(sentences):\n",
    "        sent = sentences[i]\n",
    "        # If current chunk gets too large, finalize the chunk\n",
    "        if len(cur_chunk) + len(sent) > max_chars:\n",
    "            chunks.append(cur_chunk.strip())\n",
    "            # Add overlap by recalculating starting index such that new chunk includes trailing context\n",
    "            if overlap > 0 and len(cur_chunk) > overlap:\n",
    "                # Find where to start overlap from the current chunk\n",
    "                chunk_end = cur_chunk[-overlap:]\n",
    "                # Find the index of the sentence that starts with the overlap\n",
    "                overlap_sents = []\n",
    "                overlap_len = 0\n",
    "                # Walk backwards and include enough previous sentences to reach overlap\n",
    "                for j in range(i-1, -1, -1):\n",
    "                    overlap_sents.insert(0, sentences[j])\n",
    "                    overlap_len += len(sentences[j])\n",
    "                    if overlap_len >= overlap:\n",
    "                        break\n",
    "                cur_chunk = \" \".join(overlap_sents)\n",
    "            else:\n",
    "                cur_chunk = \"\"\n",
    "        # Add next sentence to current chunk\n",
    "        cur_chunk += (\" \" if cur_chunk else \"\") + sent\n",
    "        i += 1\n",
    "    if cur_chunk:\n",
    "        chunks.append(cur_chunk.strip())\n",
    "    return chunks\n",
    "\n",
    "# Example usage:\n",
    "# semantic_chunks = semantic_chunker(raw_text, max_chars=1200, overlap=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcfcaa4-99ed-47b8-84e4-e525af7f818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunker choice #2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7afb62b6-a2ea-4447-b82d-d38ad43b366a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_parser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc_idx, page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(doc):\n\u001b[32m      8\u001b[39m     page_text = page.get_text(\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     cur_text_chunks = \u001b[43mtext_parser\u001b[49m.split_text(page_text)\n\u001b[32m     10\u001b[39m     text_chunks.extend(cur_text_chunks)\n\u001b[32m     11\u001b[39m     doc_idxs.extend([doc_idx] * \u001b[38;5;28mlen\u001b[39m(cur_text_chunks))\n",
      "\u001b[31mNameError\u001b[39m: name 'text_parser' is not defined"
     ]
    }
   ],
   "source": [
    "# example code, feel free to use in homework. \n",
    "\n",
    "text_chunks = [] # create an empty list to store the text chunks.\n",
    "doc_idxs = []    # create an empty list to store unique identifiers for the text chunks.\n",
    "\n",
    "# split the CMU handbook up into chunks and assign unique identifiers to each chunk:\n",
    "for doc_idx, page in enumerate(doc):\n",
    "    page_text = page.get_text(\"text\")\n",
    "    cur_text_chunks = text_parser.split_text(page_text)\n",
    "    text_chunks.extend(cur_text_chunks)\n",
    "    doc_idxs.extend([doc_idx] * len(cur_text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d7fe05-91a8-4a22-aca7-db6efb961634",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks # glance at the text chunks to observe how the chunks look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "928553a7-0bbf-427c-a2b0-4893bec03942",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunk_df = pd.DataFrame(text_chunks) # put the chunks into a pandas dataframe.\n",
    "text_chunk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe5f1b8c-b4ac-4d2e-a0b6-c7cd25a4bd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split resumes into sentences and include a unique identifier for each sentence:\n",
    "sentences_df = split_resumes_to_sentences(text_chunk_df, 0) \n",
    "sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30660ffe-e711-498b-bc65-f3dd19d4d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the length of the sentences dataframe:\n",
    "len(sentences_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e69bd3-6452-4038-a25a-89ce525d9eac",
   "metadata": {},
   "source": [
    "### **Choose an embedding model to use for creating embeddings of the text chunks and create the Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "94b79425-9800-41dc-88f3-4917b6d9bab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to create embeddings for the sentences:\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens') # here we are selecting to use a Bert model on HuggingFace to create the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26855dc8-ed8c-4881-9823-ba9f3b039035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sentence embeddings:\n",
    "sentence_embeddings = model.encode(sentences_df['sentence'])\n",
    "\n",
    "# check the shape of the sentence embeddings:\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95e4c22-8f3f-4f9e-b104-4f974d147955",
   "metadata": {},
   "source": [
    "## **Create a FAISS Vector Store**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "88997ec0-5616-492e-89ba-cc606e4d320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the dimensions of the sentence embeddings:\n",
    "dimension = sentence_embeddings.shape[1]\n",
    "\n",
    "# specify the number of sentences:\n",
    "nb = len(set(sentences_df))\n",
    "\n",
    "# specify the number of queries:\n",
    "nq = 10000 \n",
    "np.random.seed(1234)             # set a random number to make the process reproducible\n",
    "xb = np.random.random((nb, d)).astype('float32')\n",
    "\n",
    "#\n",
    "nlist = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cb00b265-1c79-422c-8012-a94f24899ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glance at the shape of the sentence embeddings or dimension for the vector store:\n",
    "dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d237d6f1-0b96-44d3-8661-388d7a4b994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an index for the vector store:\n",
    "index = faiss.IndexFlatL2(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e36853f3-1cbf-4012-8d59-295a67d24c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the sentence embeddings to the index:\n",
    "index.add(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b4a826a7-f9f1-4c1e-8e35-d2ec70c280a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number of vectors in the index:\n",
    "index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e8b55033-2d42-49a8-919d-48ed684f4b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the index:\n",
    "index.train(sentence_embeddings)\n",
    "\n",
    "index.is_trained  # check if index is now trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde6ca34-f789-45f3-9fb9-eb58974bb791",
   "metadata": {},
   "source": [
    "### **Construct Query and Perform Search of the Vector Store**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "43e769d0-5577-480f-8d43-c1272c41ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a query to submit to the vector store:\n",
    "question = \"<INSERT QUERY FROM HOMEWORK ASSIGNMENT INSTRUCTIONS HERE>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "92d70a36-4b5e-47ad-b6d4-cc1a1cdca198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the number of documents to retrieve from the vector store in response to the query:\n",
    "retrival_number=10\n",
    "\n",
    "# create an embedding for the query:\n",
    "query_embedding = model.encode([question])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5be560e5-25b0-44d7-9cc8-9c66f811bb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    " # measure the time it takes to search the index\n",
    "D, I = index.search(query_embedding, retrival_number)  # search the index for the query, using the number of documents to retrieve specified by k\n",
    "print(I) # print the indices of the documents that are most similar to the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ff0fd592-49f8-4a42-b098-1fd509148c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and print the string data from 'text' column of the first index in I\n",
    "\n",
    "first_index = I[0] # Get the first index from I\n",
    "\n",
    "first_row_string = sentences_df['sentence'].iloc[first_index].sum()  # Use iloc to access the row by index\n",
    "\n",
    "print(first_row_string) # Print the string data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c3a419-a504-4db6-a2e8-0ae9a040ea93",
   "metadata": {},
   "source": [
    "### **Define System Prompt (e.g. context message) to send to LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4672c947-23a1-455a-9994-daaf5ce8ea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get retrieve the results from the vector store:\n",
    "def get_sys_message(user_query: str, retrieval_number: int):\n",
    "    query_embedding = model.encode([user_query])\n",
    "    D, I = index.search(query_embedding, retrival_number)  # search\n",
    "    first_index = I[0]  # Get the first index from I\n",
    "    first_row_string = sentences_df['sentence'].iloc[first_index].sum()\n",
    "    return first_row_string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "942a72a9-9a8a-4b10-9426-9d9bf7669aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the custom function to retrieve the results from the vector store:\n",
    "get_sys_message(user_query=\"Which resume has the most software skills listed?\", retrieval_number=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b6076f29-0483-4d97-8069-d23ac1fec67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function for using an LLM with a RAG retriever:\n",
    "def rag_openAI_gpt(\n",
    "    model: str, \n",
    "    query: str, \n",
    "    retrieval_number: int, \n",
    "    llm_prompt: str):\n",
    "    \n",
    "    import openai\n",
    "    from openai import OpenAI\n",
    "    \n",
    "    client = OpenAI()\n",
    "    \n",
    "    f=get_sys_message(query, retrieval_number)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": f\"Instruction: use the information in {f} to answer the user's question.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{llm_prompt}\"},\n",
    "        {\"role\": \"assistant\", \"content\": f\"{f}\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the answer?\"}\n",
    "    ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "139db81c-c3ff-4c43-b44b-43f5b47aacf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_3_5_turbo = \"gpt-3.5-turbo\"\n",
    "gpt_4 = \"gpt-4\"\n",
    "gpt_4_turbo = \"gpt-4-0125-preview\"\n",
    "gpt_4o = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b416965f-d61f-49c8-8db0-dc2eb743e13a",
   "metadata": {},
   "source": [
    "## Examples for demonstration only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cb937223-a9a9-45d8-92e9-d9f5540c7fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_openAI_gpt(model=gpt_3_5_turbo, query=\"Which resume has the most software skills listed?\", retrieval_number=20, llm_prompt=\"Classify the document and return a label based on the document type or class. Make the label specify which occupation the document pertains to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "201c0a76-ff82-4152-938e-b8c8023506ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_openAI_gpt(model=gpt_4, query=\"Which resume has the most software skills listed?\", retrieval_number=20, llm_prompt=\"summarize the resume\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1acb53b0-2425-4731-9360-c82ed6ca6684",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_openAI_gpt(model=gpt_4_turbo, query=\"Which resume has the most software skills listed?\", retrieval_number=20, llm_prompt=\"summarize the resume\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44624b99-11f4-4047-b852-769b5ed0f2b5",
   "metadata": {},
   "source": [
    "# Homework requirement:\n",
    "\n",
    "# Section A\n",
    "\n",
    "## **Query the vector store using these queries**\n",
    "\n",
    "**Instruction: set the 'k' parameter to 5**\n",
    "\n",
    "Query 1: What is the policy statement for the academic integrity policy?\n",
    "\n",
    "Query 2: What is the policy violation definition for cheating?\n",
    "\n",
    "Query 3: What is the policy statement for improper or illegal communications?\n",
    "\n",
    "Query 4: What are CMU’s quiet hours?\n",
    "\n",
    "Query 5: Where are pets allowed on CMU?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40b493d-8963-4bad-b28d-fcd5a21a2b19",
   "metadata": {},
   "source": [
    "### ***query the vector store with the 5 queries above (don't forget to record the responses in your homework submission spreadsheet: see instructions for a link to the spreadsheet!):***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2c51d113-3e36-42d8-8bd1-a97e90a0f38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query the vector store with the 5 queries above (don't forget to record the responses in your homework submission!):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d8b400-0f50-4ab0-87d3-994923686751",
   "metadata": {},
   "source": [
    "# **Homework Questions:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862a7702-a7f1-42f0-b17d-4289df5e29e7",
   "metadata": {},
   "source": [
    "**A.I.** \n",
    "\n",
    "(i) Describe these distance metrics: Cosine similarity; Euclidean Distance; Dot Product.\n",
    "\n",
    "(ii) For each of the metrics you defined in (i), describe how the metric is different from the other metrics.\n",
    "\n",
    "(iii) For each of the metrics you defined in (i), describe one advantage and one disadvantage of using the metric.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fb24a3-d038-46cb-80a3-4ad10a1a115d",
   "metadata": {},
   "source": [
    "**A.II.** Copy and paste the results or information retrieved from the vector store in response to each of the queries you submitted to the vector store in the SPREADSHEET TEMPLATE (please see instructions for a link to the spreadsheet template you should copy and use).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581ccf17-c3c1-4b6a-a255-b128453c388a",
   "metadata": {},
   "source": [
    "**A.III.** Qualitatively analyze the responses to your queries submitted to the vector store. Did the queries retrieve the information you were expecting to obtain. Why or why not? Why do you think the queries were successful / unsuccessful in retrieving the information you expected or needed? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af4c0dc-1866-4edf-89d8-79fbb987ecdd",
   "metadata": {},
   "source": [
    "# **Section B. Experimenting with Vector Store Embeddings & Query Parameters (50 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011d0980-45c3-4745-a7ff-fa5100fdc98d",
   "metadata": {},
   "source": [
    "1) Choose 1 of the 5 queries provided in Section A, above, and experiment with submitting the query to the vector store by changing the QUERY and RETRIEVAL_NUMBER parameters in the following manner:\n",
    "\n",
    "\n",
    "*   A) Baseline query (e.g. query), retrieval_number parameter=1.\n",
    "\n",
    "*   B) Query, retrieval_number parameter  = 3\n",
    "\n",
    "*   C) Query, retrieval_number parameter  = 5\n",
    "\n",
    "*   D) Query, retrieval_number parameter  = 10\n",
    "\n",
    "**In your written homework submission, record the UNIQUE responses/results of each query submitted to the vector store.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fff92b1-6630-4735-8878-9e9b134901ed",
   "metadata": {},
   "source": [
    "2. Select a different text chunking method (e.g. word, sentence, paragraph) and:\n",
    "   \n",
    "- Chunk your text data using the method.\n",
    "- Create embeddings for the text. \n",
    "- Load the embeddings into the vector store. \n",
    "- Submit the same query you selected in B.1, above, and submit it to the vector store 6 times (using the different ‘retrieval_number’ parameter settings defined in B.1, above), and record the responses.\n",
    "\n",
    "**In your written homework submission, record the responses/results of each query submitted to the vector store.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351a7f38-d0b5-4cfa-be66-e040aecbfd16",
   "metadata": {},
   "source": [
    "### **Homework Questions:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4308cc5e-9427-487f-b767-b718da043126",
   "metadata": {},
   "source": [
    "**B.I.** Explain your rationale for selecting the query you choose in B.1. Why did you choose this query vs. the other 4 queries? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ba4b54-41a0-4a94-a38d-18aecc880459",
   "metadata": {},
   "source": [
    "**B.II.** Copy and paste the responses to the queries you submitted to the vector store in the SPREADSHEET TEMPLATE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa231e83-940a-4afb-98ec-68bc85c2cf45",
   "metadata": {},
   "source": [
    "**B.III.** Copy and paste the responses to the queries you submitted to the vector store in the SPREADSHEET TEMPLATE. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6b5f32-00d7-46b7-97a7-f043974954c0",
   "metadata": {},
   "source": [
    "**B.IV.** In observing the responses from the vector store to the queries created in B.1., which ‘k’ parameter do you think retrieved the highest quality / most accurate result? Why do you think this parameter was the best to use with the query?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3347d66-9646-49fc-b93a-5839a9d52c92",
   "metadata": {},
   "source": [
    "**B.V.** In observing the responses from the vector store to the queries created in B.2., which ‘k’ parameter do you think retrieved the highest quality / most accurate result? Why do you think this parameter was the best to use with the query?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa20517-9e92-4ac3-aa98-86308033c6c0",
   "metadata": {},
   "source": [
    "# **BONUS TASKS / QUESTIONS: Define function to call LLM API**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f31ada-df59-439e-8a11-7ffb05848002",
   "metadata": {},
   "source": [
    "## Please email Sara for the Bonus Task Python Notebook once you've completed your homework assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d904d1-c996-4f65-8457-cc93f771cd3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
